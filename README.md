# hand_gesture-Subway_surfers
Control Subway Surfers (or any arrow_key-controlled game) using hand gestures detected through your laptop webcam!

This project uses MediaPipe, OpenCV, and pynput to convert gestures into keyboard events.

ğŸš€ Features

ğŸ–ï¸ Open palm â†’ Jump

ğŸ¤™ Hang-Loose gesture (Thumb + Pinky) â†’ Duck

ğŸ‘ˆ Move hand to left side â†’ Move Left

ğŸ‘‰ Move hand to right side â†’ Move Right

ğŸ¥ Real-time hand tracking with MediaPipe

ğŸ® Works with Subway Surfers, Temple Run, or any arrow_key-based game

ğŸ’» Runs on any laptop webcam

ğŸ› ï¸ Tech Stack

> Python 3

> OpenCV

> MediaPipe

> pynput

ğŸ“¦ Installation

1ï¸âƒ£ Create Conda environment (recommended)

conda create -n subway python=3.10

conda activate subway

2ï¸âƒ£ Install dependencies

pip install opencv-python mediapipe pynput

â–¶ï¸ How to Run

python gesture_subway.py


Make sure your webcam is connected and the Subway Surfers window is focused.

âœ‹ Gestures

Gesture	Action	Description

âœ‹ Open Palm	Jump	All five fingers extended

ğŸ¤™ Hang Loose	Duck	Only thumb + pinky extended

ğŸ‘‰ Hand to Right	Move Right	Move your hand to right zone

ğŸ‘ˆ Hand to Left	Move Left	Move your hand to left zone

ğŸ“¡ How It Works

The script:

Captures webcam frames

Detects hand landmarks using MediaPipe

Checks:

Finger extension state

Handâ€™s horizontal positio

Converts gestures into keyboard events using pynput

Sends arrow keys to control the game

Lane Zones:

Left: x < 0.33

Middle: 0.33 â‰¤ x â‰¤ 0.60

Right: x > 0.60
